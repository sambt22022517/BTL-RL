{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10054171,"sourceType":"datasetVersion","datasetId":6162070}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/Farama-Foundation/MAgent2\n!pip install torch\n!pip install opencv-python","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-11-30T00:06:29.790125Z","iopub.execute_input":"2024-11-30T00:06:29.790747Z","iopub.status.idle":"2024-11-30T00:07:10.620228Z","shell.execute_reply.started":"2024-11-30T00:06:29.790699Z","shell.execute_reply":"2024-11-30T00:07:10.618922Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/Farama-Foundation/MAgent2\n  Cloning https://github.com/Farama-Foundation/MAgent2 to /tmp/pip-req-build-a_zxsm4l\n  Running command git clone --filter=blob:none --quiet https://github.com/Farama-Foundation/MAgent2 /tmp/pip-req-build-a_zxsm4l\n  Resolved https://github.com/Farama-Foundation/MAgent2 to commit b2ddd49445368cf85d4d4e1edcddae2e28aa1406\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from magent2==0.3.3) (1.26.4)\nCollecting pygame>=2.1.0 (from magent2==0.3.3)\n  Downloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: pettingzoo>=1.23.1 in /opt/conda/lib/python3.10/site-packages (from magent2==0.3.3) (1.24.0)\nRequirement already satisfied: gymnasium>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from pettingzoo>=1.23.1->magent2==0.3.3) (0.29.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3) (3.0.0)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3) (4.12.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3) (0.0.4)\nDownloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: magent2\n  Building wheel for magent2 (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for magent2: filename=magent2-0.3.3-cp310-cp310-linux_x86_64.whl size=1657646 sha256=5f2fd4becb7f0ac7331505225b9ea60cd96d0121f10d76f07e9a1cec6a4e16d5\n  Stored in directory: /tmp/pip-ephem-wheel-cache-2ggdcqbj/wheels/e4/8e/bf/51a30bc4038546e23b81c9fb513fe6a8fd916e5a9c5f4291d5\nSuccessfully built magent2\nInstalling collected packages: pygame, magent2\nSuccessfully installed magent2-0.3.3 pygame-2.6.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from magent2.environments import battle_v4\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.nn as nn\nimport random\nfrom collections import deque\nfrom IPython.display import HTML\nfrom IPython.display import FileLink\nimport copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:07:10.621715Z","iopub.execute_input":"2024-11-30T00:07:10.622085Z","iopub.status.idle":"2024-11-30T00:07:14.274219Z","shell.execute_reply.started":"2024-11-30T00:07:10.622043Z","shell.execute_reply":"2024-11-30T00:07:14.272897Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"# Env\nenv = battle_v4.env(map_size=45, render_mode=\"rgb_array\")\n\n# Model\nmodel_folder = '/kaggle/input/pretrained-qnet'\nred_model_name = 'red.pt'\nblue_model_name = '45-1024.pth'\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Result Video\nvid_dir = \"video\"\nos.makedirs(vid_dir, exist_ok=True)\nfps = 35\nvideo_name = f'red_{red_model_name.replace(\".\", \"\")} vs blue_{blue_model_name.replace(\".\", \"\")}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:15:08.794975Z","iopub.execute_input":"2024-11-30T00:15:08.795380Z","iopub.status.idle":"2024-11-30T00:15:08.826970Z","shell.execute_reply.started":"2024-11-30T00:15:08.795345Z","shell.execute_reply":"2024-11-30T00:15:08.825942Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class QNetwork(nn.Module):\n    def __init__(self, observation_shape, action_shape):\n        super().__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(observation_shape[-1], observation_shape[-1], 3),\n            nn.ReLU(),\n            nn.Conv2d(observation_shape[-1], observation_shape[-1], 3),\n            nn.ReLU(),\n        )\n        dummy_input = torch.randn(observation_shape).permute(2, 0, 1)\n        dummy_output = self.cnn(dummy_input)\n        flatten_dim = dummy_output.view(-1).shape[0]\n        self.network = nn.Sequential(\n            nn.Linear(flatten_dim, 120),\n            nn.ReLU(),\n            nn.Linear(120, 84),\n            nn.ReLU(),\n            nn.Linear(84, action_shape),\n        )\n\n    def forward(self, x):\n        assert len(x.shape) >= 3, \"only support magent input observation\"\n        x = self.cnn(x)\n        if len(x.shape) == 3:\n            batchsize = 1\n        else:\n            batchsize = x.shape[0]\n        x = x.reshape(batchsize, -1)\n        return self.network(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:15:08.994102Z","iopub.execute_input":"2024-11-30T00:15:08.994458Z","iopub.status.idle":"2024-11-30T00:15:09.002658Z","shell.execute_reply.started":"2024-11-30T00:15:08.994428Z","shell.execute_reply":"2024-11-30T00:15:09.001519Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"red_model = QNetwork(env.observation_space(\"red_0\").shape, env.action_space(\"red_0\").n).to(device)\nred_model.load_state_dict(\n    torch.load(f\"{model_folder}/{red_model_name}\", weights_only=True, map_location=device)\n)\n\nblue_model = QNetwork(env.observation_space(\"red_0\").shape, env.action_space(\"red_0\").n).to(device)\nblue_model.load_state_dict(\n    torch.load(f\"{model_folder}/{blue_model_name}\", weights_only=True, map_location=device)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:15:09.173974Z","iopub.execute_input":"2024-11-30T00:15:09.174678Z","iopub.status.idle":"2024-11-30T00:15:09.199249Z","shell.execute_reply.started":"2024-11-30T00:15:09.174642Z","shell.execute_reply":"2024-11-30T00:15:09.198201Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def make_battle_video(env, red_model, blue_model, vid_dir, fps=24, name='result', device='cpu'):\n    frames = []\n    env.reset()\n    add_frame = True\n    for agent in env.agent_iter():\n        observation, reward, termination, truncation, info = env.last()\n        observation = torch.Tensor(observation).float().permute([2, 0, 1]).unsqueeze(0).to(device)\n    \n        if termination or truncation:\n            action = None\n        else:\n            agent_handle = agent.split(\"_\")[0]\n            with torch.no_grad():\n                if agent_handle == \"blue\":\n                    q_values = blue_model(observation)\n                else:\n                    q_values = red_model(observation)\n                    # q_values = torch.randn((1, env.action_space(\"red_0\").n))\n            action = torch.argmax(q_values, dim=1).cpu().numpy()[0]\n        env.step(action)\n    \n        if 'red' in agent:\n            if add_frame:\n                frames.append(env.render())\n                add_frame = False\n        else:\n            add_frame = True\n    frames.append(env.render())\n    \n    height, width, _ = frames[0].shape\n    out = cv2.VideoWriter(\n        os.path.join(vid_dir, f\"{name}.mp4\"),\n        cv2.VideoWriter_fourcc(*\"mp4v\"),\n        fps,\n        (width, height),\n    )\n    for frame in frames:\n        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n        out.write(frame_bgr)\n    out.release()\n    print(\"Done recording pretrained agents\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:15:09.344155Z","iopub.execute_input":"2024-11-30T00:15:09.344534Z","iopub.status.idle":"2024-11-30T00:15:09.354716Z","shell.execute_reply.started":"2024-11-30T00:15:09.344488Z","shell.execute_reply":"2024-11-30T00:15:09.353579Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"make_battle_video(env, red_model, blue_model, vid_dir, fps=fps, name=video_name, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T00:15:09.853817Z","iopub.execute_input":"2024-11-30T00:15:09.854220Z","iopub.status.idle":"2024-11-30T00:15:13.129190Z","shell.execute_reply.started":"2024-11-30T00:15:09.854187Z","shell.execute_reply":"2024-11-30T00:15:13.128054Z"}},"outputs":[{"name":"stdout","text":"Done recording pretrained agents\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}